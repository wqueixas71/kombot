import streamlit as st
import google.generativeai as genai
from datetime import datetime

# Configura√ß√£o da API do Gemini usando Streamlit Secrets
genai.configure(api_key=st.secrets["gemini"]["api_key"])

# Configura o t√≠tulo e o √≠cone da p√°gina
st.set_page_config(
    page_title="Kombot",
    page_icon="üö¥‚Äç‚ôÄÔ∏è",
    layout="centered"
)

st.title("üö¥‚Äç‚ôÄÔ∏è Ol√°! Bem-vindo(a) ao Kombot")
st.caption("Como podemos te ajudar hoje?")


def convert_messages_to_history(messages, max_history=50):
    """
    Converte o formato de mensagens do Streamlit para o formato de hist√≥rico do Gemini.
    O modelo Gemini espera uma lista de dicion√°rios com 'role' e 'parts'.
    Limita o hist√≥rico para evitar contextos muito longos.
    """
    # Pega apenas as √∫ltimas N mensagens para n√£o sobrecarregar o contexto
    recent_messages = messages[-max_history:] if len(messages) > max_history else messages
    
    history = []
    for message in recent_messages:
        role = "model" if message["role"] == "assistant" else "user"
        history.append({"role": role, "parts": [message["content"]]})
    return history


@st.cache_resource(show_spinner=False)
def get_model():
    """
    Inicializa e armazena o modelo do Gemini.
    """
    model = genai.GenerativeModel(
        model_name="gemini-2.5-flash",
        system_instruction=st.secrets["llm"]["system_instruction"]
    )
    return model


def count_tokens_estimate(messages):
    """
    Estimativa simples de tokens (aproximadamente 4 caracteres = 1 token).
    """
    total_chars = sum(len(msg["content"]) for msg in messages)
    return total_chars // 4


# Inicializa o estado da sess√£o
if "messages" not in st.session_state:
    st.session_state.messages = []

if "session_start" not in st.session_state:
    st.session_state.session_start = datetime.now()

# Sidebar com controles e estat√≠sticas
with st.sidebar:
    st.header("‚öôÔ∏è Controles")
    
    # Bot√£o para limpar hist√≥rico
    if st.button("üóëÔ∏è Limpar Conversa", use_container_width=True):
        st.session_state.messages = []
        st.session_state.session_start = datetime.now()
        st.rerun()
    
    st.divider()
    
    # Estat√≠sticas da conversa
    st.header("üìä Estat√≠sticas")
    num_messages = len(st.session_state.messages)
    num_user = sum(1 for msg in st.session_state.messages if msg["role"] == "user")
    num_assistant = sum(1 for msg in st.session_state.messages if msg["role"] == "assistant")
    
    st.metric("Total de Mensagens", num_messages)
    col1, col2 = st.columns(2)
    with col1:
        st.metric("Suas", num_user)
    with col2:
        st.metric("Bot", num_assistant)
    
    # Estimativa de tokens
    if num_messages > 0:
        tokens_estimate = count_tokens_estimate(st.session_state.messages)
        st.metric("Tokens (aprox.)", f"{tokens_estimate:,}")
    
    # Tempo de sess√£o
    session_duration = datetime.now() - st.session_state.session_start
    minutes = int(session_duration.total_seconds() / 60)
    st.metric("Dura√ß√£o da Sess√£o", f"{minutes} min")
    
    st.divider()
    
    # Configura√ß√µes
    st.header("üéõÔ∏è Configura√ß√µes")
    use_streaming = st.checkbox("Resposta em tempo real", value=True)
    max_history = st.slider(
        "M√°ximo de mensagens no contexto",
        min_value=10,
        max_value=100,
        value=50,
        step=10,
        help="Limita quantas mensagens anteriores o bot considera"
    )

# Exibe o hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Campo de entrada do chat
if prompt := st.chat_input("Como podemos te ajudar?"):
    # Adiciona a mensagem do usu√°rio ao hist√≥rico
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # Exibe a mensagem do usu√°rio
    with st.chat_message("user"):
        st.markdown(prompt)

    # Gera e exibe a resposta do assistente
    with st.chat_message("assistant"):
        chat_model = get_model()
        
        # Converte apenas as mensagens anteriores (sem a √∫ltima do usu√°rio)
        history_for_gemini = convert_messages_to_history(
            st.session_state.messages[:-1],
            max_history=max_history
        )
        
        # Inicia a sess√£o de chat com o hist√≥rico
        chat_session = chat_model.start_chat(history=history_for_gemini)
        
        try:
            if use_streaming:
                # Resposta em streaming (tempo real)
                response_placeholder = st.empty()
                full_response = ""
                
                with st.spinner("Pensando..."):
                    response = chat_session.send_message(prompt, stream=True)
                    
                    for chunk in response:
                        if chunk.text:
                            full_response += chunk.text
                            response_placeholder.markdown(full_response + "‚ñå")
                    
                    # Remove o cursor de digita√ß√£o
                    response_placeholder.markdown(full_response)
                
                # Adiciona a resposta completa ao hist√≥rico
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": full_response
                })
            else:
                # Resposta tradicional (tudo de uma vez)
                with st.spinner("Gerando resposta..."):
                    response = chat_session.send_message(prompt)
                    st.markdown(response.text)
                    
                    # Adiciona a resposta ao hist√≥rico
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": response.text
                    })
            
        except genai.types.generation_types.BlockedPromptException:
            st.warning(
                "‚ö†Ô∏è Desculpe, sua solicita√ß√£o foi bloqueada por raz√µes de seguran√ßa. "
                "Por favor, tente uma pergunta diferente."
            )
            # Remove a √∫ltima mensagem do usu√°rio
            st.session_state.messages.pop()
            
        except Exception as e:
            st.error(
                "‚ùå Ocorreu um erro ao processar sua mensagem. "
                "Por favor, tente novamente."
            )
            # Mostra detalhes do erro em modo expandido
            with st.expander("Ver detalhes do erro"):
                st.exception(e)
            # Remove a √∫ltima mensagem do usu√°rio
            st.session_state.messages.pop()

# Mensagem quando n√£o h√° hist√≥rico
if len(st.session_state.messages) == 0:
    st.info("üëã Ol√°! Sou o Kombot. Fa√ßa sua primeira pergunta para come√ßarmos nossa conversa!")